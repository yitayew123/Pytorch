{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb221db-2373-46c2-8be1-fb1bbf707255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2d9190-2896-49a3-87ae-ac4e0fe819ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dcf5e4-db4d-4d79-800d-2df530b60e65",
   "metadata": {},
   "source": [
    "## What is PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f61c0-79c3-43c8-bd32-924b983bf45d",
   "metadata": {},
   "source": [
    "* PyTorch is an open-source deep learning framework developed by Facebook's AI Research (FAIR) lab. It provides a flexible and efficient platform for building and training deep learning models. PyTorch is particularly popular for research and development because of its dynamic computation graph, which allows developers to modify the graph on-the-fly during execution.\n",
    "\n",
    "#### Key features of PyTorch include:\n",
    "\n",
    "* **Tensors**: Multidimensional arrays with GPU acceleration.\n",
    "* **Autograd**: Automatic differentiation for dynamic computation graphs.\n",
    "* **Torch.nn**: Modules for building neural networks.\n",
    "* **Optimizers**: Tools for gradient-based optimization.\n",
    "* **Data Loading Utilities**: Built-in support for handling datasets and creating data pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc4371-0418-430b-9188-9958282fd649",
   "metadata": {},
   "source": [
    "## 1. Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3f3e4b-243b-456a-a78f-672d8f25f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc146b9-fa9d-46f2-995f-4ad7165989d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([1,2,3,4,5])\n",
    "type(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "354e9ac1-70f7-483d-bf7d-a7c1053ddd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0850c8c-1428-42e7-afb8-4b18692d6bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6fc3408-f40b-4aca-8359-d270991372c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5], dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(array)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650f495d-3dc4-487c-9341-95e0a4143862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor from a Python list\n",
    "tensor = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b1bf74-bbc4-41a8-8119-df7ca1adbf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6323, 0.9582, 0.2830],\n",
      "        [0.3208, 0.0547, 0.2612]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor with random values\n",
    "random_tensor = torch.rand(2, 3)  # 2x3 matrix with values between 0 and 1\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3309242a-39a8-41e3-90da-053abe6d926d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor of zeros\n",
    "zeros_tensor = torch.zeros(2, 3)  # 2x3 matrix with all elements as 0\n",
    "print(zeros_tensor)\n",
    "\n",
    "# Tensor of ones\n",
    "ones_tensor = torch.ones(2, 3)  # 2x3 matrix with all elements as 1\n",
    "print(ones_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dbbc91-49fe-48ed-aeae-5fe67e962f40",
   "metadata": {},
   "source": [
    "## 2. Tensor Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c21bcb68-0225-4560-8b52-981fb86ef7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: tensor([5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Element-wise addition\n",
    "sum_tensor = a + b\n",
    "print(\"Sum:\", sum_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384907ab-5a56-4c66-b80f-2f3b6d9280c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference: tensor([-3, -3, -3])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise subtraction\n",
    "diff_tensor = a - b\n",
    "print(\"Difference:\", diff_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec82461-5a8f-42d2-a7c7-db29ca59e7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "prod_tensor = a * b\n",
    "print(\"Product:\", prod_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1d56def-5bc5-4916-a4e6-2a2e649c1258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix product: \n",
      " tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Matrix multiplication\n",
    "matrix_prod = torch.matmul(a, b)\n",
    "print(\"Matrix product: \\n\", matrix_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba6db9-9211-4499-be9b-55cde380a56b",
   "metadata": {},
   "source": [
    "## 3. Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10b9d8cd-8184-4d77-82a7-aa4815671358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped tensor:\n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Reshaping to a different size\n",
    "reshaped_tensor = tensor.view(3, 2)  # 3x2 tensor\n",
    "print(\"Reshaped tensor:\\n\", reshaped_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16b1a572-569d-4b9a-a080-841f7a03afdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened tensor: tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Flattening the tensor to a 1D vector\n",
    "flattened_tensor = tensor.view(-1)\n",
    "print(\"Flattened tensor:\", flattened_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1921375-8ffd-4a9e-a00a-5d5b5d186853",
   "metadata": {},
   "source": [
    "## 4. Slicing and Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea978a0f-1707-4bfc-835d-f32be0ad0a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element: tensor(2)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Access a specific element\n",
    "element = tensor[0, 1]  # First row, second column\n",
    "print(\"Element:\", element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1162fc9c-f4de-4747-a56d-2458047381b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliced tensor:\n",
      " tensor([[2, 3],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Slice a part of the tensor\n",
    "slice_tensor = tensor[:, 1:]  # All rows, from second column onward\n",
    "print(\"Sliced tensor:\\n\", slice_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38893f81-92fb-44ca-b211-16877680c4c3",
   "metadata": {},
   "source": [
    "## 5. Tensor Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "618d6e1c-1b1e-4336-9212-9d6921380426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated along rows:\n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "concat_tensor = torch.cat((a, b), dim=0)  # Concatenate along rows\n",
    "print(\"Concatenated along rows:\\n\", concat_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "916e3e72-d7e3-4a85-8ad8-34972be092e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available (i.e., if GPU is available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33437b01",
   "metadata": {},
   "source": [
    "#### Moving tensors to GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b45f872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor on GPU: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Move tensor to GPU\n",
    "tensor_gpu = tensor.to(device)\n",
    "print(\"Tensor on GPU:\", tensor_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc211a",
   "metadata": {},
   "source": [
    "### random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea4dc13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7804, 0.2976, 0.6380, 0.6616],\n",
      "        [0.8010, 0.7766, 0.2814, 0.4252],\n",
      "        [0.3752, 0.7664, 0.3998, 0.1271]])\n"
     ]
    }
   ],
   "source": [
    "# creating rondom tensor of size (3,4)\n",
    "random_tensor=torch.rand(3,4)\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39fd76f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1271)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor[0,2]\n",
    "random_tensor[2][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16d33469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dee9982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3611, 0.4180, 0.7327],\n",
      "         [0.7409, 0.0981, 0.7137],\n",
      "         [0.3223, 0.0812, 0.4970],\n",
      "         ...,\n",
      "         [0.1273, 0.5102, 0.1866],\n",
      "         [0.6871, 0.3355, 0.1984],\n",
      "         [0.1748, 0.2814, 0.1097]],\n",
      "\n",
      "        [[0.4889, 0.6480, 0.1263],\n",
      "         [0.4818, 0.1061, 0.2676],\n",
      "         [0.6377, 0.8582, 0.0543],\n",
      "         ...,\n",
      "         [0.6525, 0.4904, 0.0926],\n",
      "         [0.7001, 0.3462, 0.3682],\n",
      "         [0.8330, 0.9064, 0.6896]],\n",
      "\n",
      "        [[0.9858, 0.1236, 0.1524],\n",
      "         [0.2821, 0.6085, 0.2422],\n",
      "         [0.3807, 0.5868, 0.2977],\n",
      "         ...,\n",
      "         [0.8413, 0.9297, 0.1328],\n",
      "         [0.5697, 0.4044, 0.7414],\n",
      "         [0.0047, 0.1777, 0.7397]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4931, 0.7438, 0.4454],\n",
      "         [0.9334, 0.0509, 0.3136],\n",
      "         [0.1767, 0.8169, 0.4193],\n",
      "         ...,\n",
      "         [0.8922, 0.0564, 0.9778],\n",
      "         [0.6191, 0.9842, 0.3849],\n",
      "         [0.8275, 0.7099, 0.0665]],\n",
      "\n",
      "        [[0.3393, 0.9749, 0.7797],\n",
      "         [0.3651, 0.4507, 0.5613],\n",
      "         [0.3246, 0.2240, 0.2840],\n",
      "         ...,\n",
      "         [0.9174, 0.2657, 0.2142],\n",
      "         [0.8119, 0.6878, 0.1169],\n",
      "         [0.8951, 0.6744, 0.3552]],\n",
      "\n",
      "        [[0.5826, 0.1020, 0.4088],\n",
      "         [0.6694, 0.8744, 0.0599],\n",
      "         [0.4613, 0.0342, 0.7099],\n",
      "         ...,\n",
      "         [0.4481, 0.2104, 0.5645],\n",
      "         [0.6466, 0.8746, 0.3352],\n",
      "         [0.8156, 0.8389, 0.2041]]])\n"
     ]
    }
   ],
   "source": [
    "#creating image tensor with height, width and color channel\n",
    "image_tensor = torch.rand(size=(3, 224,224)) # 3 color channels, 224x224 image\n",
    "print(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a57d641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of your tensor is: torch.Size([224, 224, 3])\n",
      "the dimension of your tensor is: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of your tensor is:\",image_tensor.shape)# shape of the tensor\n",
    "print (\"the dimension of your tensor is:\",image_tensor.ndim)# dimension of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d54ba058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  3.,  5.,  7.,  9., 11., 13., 15., 17., 19., 21., 23., 25., 27.,\n",
      "        29., 31., 33., 35., 37., 39., 41., 43., 45., 47., 49., 51., 53., 55.,\n",
      "        57., 59., 61., 63., 65., 67., 69., 71., 73., 75., 77., 79., 81., 83.,\n",
      "        85., 87., 89., 91., 93., 95., 97., 99.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yitayew\\AppData\\Local\\Temp\\ipykernel_3708\\4227904330.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  range = torch.range(start= 1, step=2,end=100)\n"
     ]
    }
   ],
   "source": [
    "# range of values in the tensor\n",
    "# range = torch.range(00,10)\n",
    "range = torch.range(start= 1, step=2,end=100)\n",
    "print(range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101af1c9",
   "metadata": {},
   "source": [
    "### Tensor data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4205866",
   "metadata": {},
   "source": [
    "In the context of machine learning and deep learning, tensors are multi-dimensional arrays, serving as the fundamental data structure for neural network computations. They generalize matrices to higher dimensions and can represent scalars, vectors, matrices, or higher-dimensional data. Below are common tensor types and their explanations with examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0b5184",
   "metadata": {},
   "source": [
    "1. Scalar (0-D Tensor)\n",
    "\n",
    "    Description: A tensor with zero dimensions containing a single numerical value.\n",
    "    Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "583f4a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values of the scallar tensor(12)\n",
      "items of the scallar 12\n",
      "data type of the scallar torch.int64\n",
      "dimension of the scallar 0\n",
      "shape of the scallaer torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(12)\n",
    "print(\"values of the scallar\",scalar)\n",
    "print(\"items of the scallar\",scalar.item())\n",
    "print(\"data type of the scallar\",scalar.dtype)\n",
    "print(\"dimension of the scallar\",scalar.ndim)\n",
    "print(\"shape of the scallaer\",scalar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32aa381",
   "metadata": {},
   "source": [
    "2. Vector (1-D Tensor)\n",
    "\n",
    "    Description: A one-dimensional array of values, often representing a sequence or a set of features.\n",
    "    * Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65ede772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the values of the vector tensor([1, 2, 3, 4, 5])\n",
      "data type of the vector torch.int64\n",
      "shape the vector is: torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# creating a vector\n",
    "list = [1,2,3,4,5]\n",
    "vector_data = torch.tensor(list)\n",
    "print(\"the values of the vector\",vector_data)\n",
    "print(\"data type of the vector\",vector_data.dtype)\n",
    "print(\"shape the vector is:\", vector_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648826ae",
   "metadata": {},
   "source": [
    "3. Matrix (2-D Tensor)\n",
    "\n",
    "    Description: A two-dimensional array, similar to a table with rows and columns.\n",
    "    Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01b289e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the values of the matrix tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "the data type of the marics is: torch.int64\n",
      "the shape of the matrix is: torch.Size([3, 3])\n",
      "the dimension of the matrix is: 2\n",
      "the size of the matrix is: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# creating a matrix\n",
    "list2 = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "matrix_vector = torch.tensor(list2)\n",
    "print(\"the values of the matrix\",matrix_vector)\n",
    "print('the data type of the marics is:',matrix_vector.dtype)\n",
    "print('the shape of the matrix is:',matrix_vector.shape)\n",
    "print('the dimension of the matrix is:',matrix_vector.ndim)\n",
    "print('the size of the matrix is:',matrix_vector.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619341fe",
   "metadata": {},
   "source": [
    "4. 3-D Tensor\n",
    "\n",
    "    Description: A tensor with three dimensions, often used to represent data like images (height × width × channels).\n",
    "    Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10ed3cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the values of the 3D tensor\n",
      " tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]]])\n",
      "the data type of the 3D tensor is\n",
      ": torch.int64\n",
      "the shape of the 3D tensor is\n",
      ": torch.Size([2, 3, 3])\n",
      "the dimension of the 3D tensor is\n",
      ": 3\n",
      "the size of the 3D tensor is\n",
      ": torch.Size([2, 3, 3])\n",
      "the shape of the 3D tensor is\n",
      ": torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# creating a 3D tensor\n",
    "list3 = [[[1,2,3],[4,5,6],[7,8,9]],[[10,11,12],[13,14,15],[16,17,18]]]\n",
    "tensor_3d = torch.tensor(list3)\n",
    "print(\"the values of the 3D tensor\\n\",tensor_3d)\n",
    "print('the data type of the 3D tensor is\\n:',tensor_3d.dtype)\n",
    "print('the shape of the 3D tensor is\\n:',tensor_3d.shape)\n",
    "print('the dimension of the 3D tensor is\\n:',tensor_3d.ndim)\n",
    "print('the size of the 3D tensor is\\n:',tensor_3d.size())\n",
    "print('the shape of the 3D tensor is\\n:',tensor_3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7bf8e",
   "metadata": {},
   "source": [
    "5. N-Dimensional Tensor (N-D Tensor)\n",
    "\n",
    "    Description: A tensor with more than three dimensions, often used in complex data like videos (time × height × width × channels) or higher-dimensional feature spaces.\n",
    "    Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54e04fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the values of the 4D tensor\n",
      " tensor([[[[ 1,  2],\n",
      "          [ 3,  4]],\n",
      "\n",
      "         [[ 5,  6],\n",
      "          [ 7,  8]]],\n",
      "\n",
      "\n",
      "        [[[ 9, 10],\n",
      "          [11, 12]],\n",
      "\n",
      "         [[13, 14],\n",
      "          [15, 16]]]])\n",
      "the data type of the 4D tensor is\n",
      ": torch.int64\n",
      "the shape of the 4D tensor is\n",
      ": torch.Size([2, 2, 2, 2])\n",
      "the dimension of the 4D tensor is\n",
      ": 4\n",
      "the size of the 4D tensor is\n",
      ": torch.Size([2, 2, 2, 2])\n",
      "the shape of the 4D tensor is\n",
      ": torch.Size([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "#create a 4D tensor\n",
    "list4 = [[[[1,2],[3,4]],[[5,6],[7,8]]],[[[9,10],[11,12]],[[13,14],[15,16]]]]\n",
    "tensor_4d = torch.tensor(list4)\n",
    "print(\"the values of the 4D tensor\\n\",tensor_4d)\n",
    "print('the data type of the 4D tensor is\\n:',tensor_4d.dtype)\n",
    "print('the shape of the 4D tensor is\\n:',tensor_4d.shape)\n",
    "print('the dimension of the 4D tensor is\\n:',tensor_4d.ndim)\n",
    "print('the size of the 4D tensor is\\n:',tensor_4d.size())\n",
    "print('the shape of the 4D tensor is\\n:',tensor_4d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c815fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
